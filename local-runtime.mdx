---
title: "Local Runtime Testing (Laddr with OpenAI)"
description: "Documentation for running Laddr locally using python main.py with in-memory queue and SQLite backend."
---

# Local Runtime Testing (Laddr with OpenAI)

This document covers **local testing and validation** of Laddr agents using  
`python main.py run {...}` with an **in-memory queue** and **SQLite database**.  
No Docker or Redis setup is required ‚Äî ideal for debugging, development, and performance benchmarking.

---

## Executive Summary

‚úÖ Single and sequential agent workflows verified  
‚úÖ In-memory queue (MemoryBus) operational  
‚úÖ SQLite traces functional and complete  
‚ö†Ô∏è Delegation requires worker processes (multi-process mode)  

---

## Configuration

Set up your environment file:

<CodeBlock
  code={`LLM_BACKEND=openai
QUEUE_BACKEND=memory
DB_BACKEND=sqlite
DATABASE_URL=sqlite:///./Laddr.db

OPENAI_API_KEY=sk-proj-***
RESEARCHER_MODEL=gpt-4o-mini
COORDINATOR_MODEL=gpt-4o-mini
ANALYZER_MODEL=gpt-4o-mini
WRITER_MODEL=gpt-4o-mini
VALIDATOR_MODEL=gpt-4o-mini`}
  language="bash"
/>

> üí° **Note:** No Redis or Docker dependencies are required.  
> SQLite stores traces locally in `Laddr.db`.

---

## Test Scenarios

### Single Agent
<CodeBlock
  code={`AGENT_NAME=writer python main.py run '{"query": "Write about AI"}'`}
  language="bash"
/>

### Analyzer with Tools
<CodeBlock
  code={`AGENT_NAME=analyzer python main.py run '{"query": "Calculate 100 + 200 + 300"}'`}
  language="bash"
/>

### Sequential Workflow
<CodeBlock
  code={`from Laddr import AgentRunner, LaddrConfig
import asyncio, uuid

async def test():
    runner = AgentRunner(env_config=LaddrConfig())
    job_id = str(uuid.uuid4())
    inputs = {'query': 'Calculate 100 + 200 + 300'}

    for agent in ['analyzer', 'writer']:
        result = await runner.run(inputs, agent_name=agent, job_id=job_id)
        if result.get('status') == 'success':
            inputs = {'input': result['result']}

asyncio.run(test())`}
  language="python"
/>

---

## Debugging and Traces

Traces are stored in SQLite:
<CodeBlock
  code={`sqlite3 Laddr.db "SELECT agent_name, event_type, timestamp FROM traces ORDER BY id DESC LIMIT 10;"`}
  language="bash"
/>

Common events:
- `task_start`, `task_complete`
- `llm_usage`, `tool_call`, `tool_error`
- `autonomous_think`

---

## Running Workers Locally

To start an agent worker process locally, run the worker script for the agent you want to start. For example:

<CodeBlock code={`python agents/coordinator.py`} language="bash" />

You can run multiple workers by opening multiple terminals and starting different agent processes (or multiple instances of the same agent). Example:

<CodeBlock
  code={`# Terminal 1
python agents/coordinator.py

# Terminal 2
python agents/researcher.py

# Terminal 3
python agents/writer.py`}
  language="bash"
/>

Note: delegation (agents handing tasks to other workers) requires a queue backend such as Redis or Kafka to route tasks between processes. Local in-process running (MemoryBus / in-memory queue) is ideal for single-agent testing and debugging but does not support inter-process delegation.

---

## Known Limitations

- ‚ö†Ô∏è Delegation tools require separate worker processes  
- ‚ö†Ô∏è `MemoryBus` only supports single-process communication  
- ‚ö†Ô∏è Some agents may overuse delegation ‚Äî refine instructions

---

## Guidelines

- ‚úÖ Use single-agent mode for debugging  
- ‚úÖ Use sequential mode for chained workflows  
- ‚öôÔ∏è Inspect traces to verify execution  
- üö´ Avoid delegation without workers  

---

## Notes

üß† `MemoryBus` is a singleton that handles agent task routing in the same process.  
üóÑÔ∏è SQLite logging ensures full trace visibility for debugging.  
üöÄ For distributed execution, switch to `QUEUE_BACKEND=redis`.

---
